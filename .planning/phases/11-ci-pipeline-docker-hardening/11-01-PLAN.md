---
phase: 11-ci-pipeline-docker-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - services/url-api/internal/config/config.go
  - services/analytics-rpc/internal/config/config.go
  - services/analytics-consumer/internal/config/config.go
  - services/url-api/internal/svc/servicecontext.go
  - services/analytics-rpc/internal/svc/servicecontext.go
  - services/analytics-consumer/internal/svc/servicecontext.go
  - services/url-api/etc/url.yaml
  - services/url-api/etc/url-docker.yaml
  - services/analytics-rpc/etc/analytics.yaml
  - services/analytics-rpc/etc/analytics-docker.yaml
  - services/analytics-consumer/etc/consumer.yaml
  - services/analytics-consumer/etc/consumer-docker.yaml
  - services/analytics-consumer/consumer.go
  - services/url-api/internal/handler/routes.go
autonomous: true

must_haves:
  truths:
    - "PostgreSQL connection pool is explicitly configured with MaxOpenConns, MaxIdleConns, ConnMaxLifetime for all three services"
    - "Pool configuration is driven by YAML config files with conservative defaults (MaxOpen=10, MaxIdle=5, MaxLifetime=1h)"
    - "Active pool configuration is logged at startup for each service"
    - "GET /healthz on url-api returns 200 OK"
    - "analytics-consumer has a healthz endpoint on port 8082 returning 200 OK"
    - "analytics-rpc healthz is accessible (via DevServer or custom endpoint)"
  artifacts:
    - path: "services/url-api/internal/config/config.go"
      provides: "PoolConfig struct with MaxOpenConns, MaxIdleConns, ConnMaxLifetime"
      contains: "PoolConfig"
    - path: "services/url-api/internal/svc/servicecontext.go"
      provides: "Connection pool configuration applied to sqlx connection"
      contains: "SetMaxOpenConns"
    - path: "services/analytics-consumer/consumer.go"
      provides: "Separate health check HTTP server on dedicated port"
      contains: "healthz"
  key_links:
    - from: "services/url-api/internal/config/config.go"
      to: "services/url-api/etc/url.yaml"
      via: "YAML config loading"
      pattern: "Pool"
    - from: "services/url-api/internal/svc/servicecontext.go"
      to: "database/sql"
      via: "conn.RawDB() pool configuration"
      pattern: "SetMaxOpenConns"
---

<objective>
Add PostgreSQL connection pool configuration and health check endpoints to all three services.

Purpose: Explicitly control database connection pool behavior (preventing pool exhaustion under load) and provide liveness endpoints for Docker/Kubernetes health probes across all services.

Output: All services have config-driven pool settings logged at startup, url-api has /healthz route, analytics-rpc uses DevServer healthz, and analytics-consumer runs a separate lightweight HTTP server for health checks.
</objective>

<execution_context>
@/Users/baotoq/.claude/get-shit-done/workflows/execute-plan.md
@/Users/baotoq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@services/url-api/internal/config/config.go
@services/analytics-rpc/internal/config/config.go
@services/analytics-consumer/internal/config/config.go
@services/url-api/internal/svc/servicecontext.go
@services/analytics-rpc/internal/svc/servicecontext.go
@services/analytics-consumer/internal/svc/servicecontext.go
@services/analytics-consumer/consumer.go
@services/url-api/url.go
@services/url-api/internal/handler/routes.go
@services/url-api/etc/url.yaml
@services/url-api/etc/url-docker.yaml
@services/analytics-rpc/etc/analytics.yaml
@services/analytics-rpc/etc/analytics-docker.yaml
@services/analytics-consumer/etc/consumer.yaml
@services/analytics-consumer/etc/consumer-docker.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add PostgreSQL connection pool configuration to all services</name>
  <files>
    services/url-api/internal/config/config.go
    services/analytics-rpc/internal/config/config.go
    services/analytics-consumer/internal/config/config.go
    services/url-api/internal/svc/servicecontext.go
    services/analytics-rpc/internal/svc/servicecontext.go
    services/analytics-consumer/internal/svc/servicecontext.go
    services/url-api/etc/url.yaml
    services/url-api/etc/url-docker.yaml
    services/analytics-rpc/etc/analytics.yaml
    services/analytics-rpc/etc/analytics-docker.yaml
    services/analytics-consumer/etc/consumer.yaml
    services/analytics-consumer/etc/consumer-docker.yaml
  </files>
  <action>
    Add a `PoolConfig` struct to each service's config package with three fields:
    - `MaxOpenConns int` with json tag `json:",default=10"`
    - `MaxIdleConns int` with json tag `json:",default=5"`
    - `ConnMaxLifetime int` with json tag `json:",default=3600"` (seconds, because go-zero json doesn't parse duration strings; convert to time.Duration in ServiceContext)

    Add `Pool PoolConfig` field to each service's Config struct.

    In each service's `NewServiceContext()`:
    1. After creating `sqlx.NewSqlConn("postgres", c.DataSource)`, call `conn.RawDB()` to get the underlying `*sql.DB`
    2. Call `db.SetMaxOpenConns(c.Pool.MaxOpenConns)`, `db.SetMaxIdleConns(c.Pool.MaxIdleConns)`, `db.SetConnMaxLifetime(time.Duration(c.Pool.ConnMaxLifetime) * time.Second)`
    3. Log the active pool configuration using `logx.Infof("Connection pool configured: MaxOpen=%d, MaxIdle=%d, MaxLifetime=%ds", c.Pool.MaxOpenConns, c.Pool.MaxIdleConns, c.Pool.ConnMaxLifetime)`
    4. If `conn.RawDB()` returns an error, use `logx.Must(err)` to fatal

    Note: If default values from go-zero json tags work (i.e., when Pool is not in YAML, defaults apply), then YAML files don't strictly need Pool section. But for explicitness and per user decision to "log active pool configuration at startup for visibility," add the Pool section to ALL 6 YAML files (3 local + 3 docker) with the conservative defaults:

    ```yaml
    Pool:
      MaxOpenConns: 10
      MaxIdleConns: 5
      ConnMaxLifetime: 3600
    ```

    Import `time` and `github.com/zeromicro/go-zero/core/logx` in each ServiceContext file as needed.

    The PoolConfig struct can be defined in each service's config package independently (same struct, 3 places) since the services are separate packages. This keeps each service self-contained per user decision: "Each service has its own independent pool config fields."
  </action>
  <verify>
    Run `go build ./services/url-api/... && go build ./services/analytics-rpc/... && go build ./services/analytics-consumer/...` to verify compilation.
    Run `go test ./services/...` to verify existing tests still pass.
  </verify>
  <done>
    All three services compile with PoolConfig in config, ServiceContext applies pool settings via RawDB(), and pool configuration is logged at startup via logx.Infof.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add health check endpoints to all services</name>
  <files>
    services/url-api/internal/handler/routes.go
    services/analytics-consumer/consumer.go
  </files>
  <action>
    **url-api /healthz:**
    The routes.go file is generated by goctl (DO NOT EDIT comment at top). However, looking at the user's url.go entry point, we can add the healthz route AFTER RegisterHandlers in url.go. Actually, the cleaner approach: add a manual healthz route in url.go using `server.AddRoute()` AFTER `handler.RegisterHandlers(server, ctx)`:

    ```go
    // Health check endpoint
    server.AddRoute(rest.Route{
        Method:  http.MethodGet,
        Path:    "/healthz",
        Handler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            w.WriteHeader(http.StatusOK)
            w.Write([]byte("ok"))
        }),
    })
    ```

    This avoids editing the generated routes.go file. Add this in `services/url-api/url.go` after the `handler.RegisterHandlers(server, ctx)` line. Import `net/http` (already imported) and `github.com/zeromicro/go-zero/rest` (already imported).

    **analytics-rpc healthz:**
    The DevServer is already configured in analytics-rpc's YAML with `HealthPath: /healthz`. go-zero's DevServer automatically serves a health endpoint at the configured path on the DevServer port (6471). No code changes needed for analytics-rpc -- it already has `/healthz` on port 6471 via DevServer. Verify this by checking the YAML config has `DevServer.HealthPath: /healthz`.

    **analytics-consumer healthz:**
    The consumer has no HTTP server. Per user decision, add a lightweight HTTP health server on a dedicated port. Add a `HealthCheckPort` field to the consumer's config:

    ```go
    type Config struct {
        service.ServiceConf
        DataSource     string
        KqConsumerConf kq.KqConf
        GeoIPPath      string `json:",optional"`
        HealthCheckPort int    `json:",default=8082"`
    }
    ```

    In `consumer.go` main(), start a separate goroutine with a health check HTTP server BEFORE `group.Start()`:

    ```go
    // Start health check server
    go func() {
        mux := http.NewServeMux()
        mux.HandleFunc("/healthz", func(w http.ResponseWriter, r *http.Request) {
            w.WriteHeader(http.StatusOK)
            w.Write([]byte("ok"))
        })
        addr := fmt.Sprintf(":%d", c.HealthCheckPort)
        logx.Infof("Health check server listening on %s", addr)
        if err := http.ListenAndServe(addr, mux); err != nil && err != http.ErrServerClosed {
            logx.Errorf("Health server error: %v", err)
        }
    }()
    ```

    Import `net/http` and `github.com/zeromicro/go-zero/core/logx` in consumer.go.

    Add `HealthCheckPort: 8082` to both consumer YAML files (consumer.yaml and consumer-docker.yaml).

    Update docker-compose.yml to expose port 8082 for analytics-consumer:
    ```yaml
    analytics-consumer:
      ports:
        - "6472:6472"
        - "8082:8082"
    ```

    Update Dockerfile to expose port 8082 for analytics-consumer stage:
    ```dockerfile
    EXPOSE 6472 8082
    ```

    This is a liveness-only check: just confirms the process is running and can respond to HTTP. No database or Kafka checks (per user decision: "Health = liveness check").
  </action>
  <verify>
    Run `go build ./services/url-api/... && go build ./services/analytics-rpc/... && go build ./services/analytics-consumer/...` to verify compilation.
    Run `go test ./services/...` to verify existing tests still pass.
  </verify>
  <done>
    url-api has /healthz on port 8080 returning 200 "ok". analytics-rpc uses DevServer /healthz on port 6471. analytics-consumer has separate health HTTP server on port 8082 with /healthz returning 200 "ok". Docker Compose exposes the consumer health port.
  </done>
</task>

</tasks>

<verification>
1. `go build ./services/...` compiles all three services without errors
2. `go test ./services/...` all existing tests pass
3. Pool config structs exist in all three config packages with default values
4. ServiceContext files call RawDB() and set pool parameters
5. logx.Infof pool log message present in all three ServiceContext files
6. url-api url.go has /healthz route added
7. analytics-consumer has HealthCheckPort config and separate health server goroutine
8. All 6 YAML files have Pool section with MaxOpenConns=10, MaxIdleConns=5, ConnMaxLifetime=3600
9. Docker Compose exposes port 8082 for analytics-consumer
</verification>

<success_criteria>
- All three services compile and existing tests pass
- Pool configuration logged at startup for each service
- /healthz endpoints respond with 200 OK on all services (url-api:8080, analytics-rpc:6471 via DevServer, analytics-consumer:8082)
</success_criteria>

<output>
After completion, create `.planning/phases/11-ci-pipeline-docker-hardening/11-01-SUMMARY.md`
</output>
