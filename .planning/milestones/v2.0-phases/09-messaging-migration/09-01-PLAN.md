---
phase: 09-messaging-migration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docker-compose.yml
  - services/migrations/000003_add_clicks_enrichment.up.sql
  - services/migrations/000003_add_clicks_enrichment.down.sql
  - Makefile
  - go.mod
  - go.sum
  - services/analytics-consumer/consumer.go
  - services/analytics-consumer/etc/consumer.yaml
  - services/analytics-consumer/internal/config/config.go
  - services/analytics-consumer/internal/svc/servicecontext.go
autonomous: true

must_haves:
  truths:
    - "Kafka broker starts and accepts connections on localhost:9092"
    - "click-events topic exists or auto-creates on first publish"
    - "clicks table has country_code, device_type, traffic_source columns"
    - "analytics-consumer service scaffold compiles without errors"
  artifacts:
    - path: "docker-compose.yml"
      provides: "Kafka broker in KRaft mode alongside PostgreSQL"
      contains: "kafka"
    - path: "services/migrations/000003_add_clicks_enrichment.up.sql"
      provides: "ALTER TABLE adding enrichment columns to clicks"
      contains: "country_code"
    - path: "services/analytics-consumer/consumer.go"
      provides: "Consumer service main entry point"
      contains: "kq.MustNewQueue"
    - path: "services/analytics-consumer/internal/config/config.go"
      provides: "Consumer config with Kafka and DataSource"
      contains: "KqConsumerConf"
  key_links:
    - from: "docker-compose.yml"
      to: "localhost:9092"
      via: "Kafka broker port mapping"
      pattern: "9092:9092"
    - from: "services/analytics-consumer/consumer.go"
      to: "services/analytics-consumer/internal/config/config.go"
      via: "conf.MustLoad"
      pattern: "conf\\.MustLoad"
---

<objective>
Set up Kafka infrastructure (KRaft mode, no ZooKeeper) in Docker Compose, add enrichment columns to the clicks table, install go-queue and enrichment dependencies, and scaffold the analytics-consumer service with config/svc/main entry point.

Purpose: Foundation for event-driven analytics pipeline. Kafka must be running and clicks table must support enrichment fields before publisher and consumer can be implemented.

Output: Kafka running in Docker, clicks table with country_code/device_type/traffic_source columns, analytics-consumer service scaffold that compiles and starts (with placeholder handler).
</objective>

<execution_context>
@/Users/baotoq/.claude/get-shit-done/workflows/execute-plan.md
@/Users/baotoq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-messaging-migration/09-RESEARCH.md
@docker-compose.yml
@Makefile
@services/migrations/000002_create_clicks.up.sql
@services/analytics-rpc/model/clicksmodel_gen.go
@go.mod
</context>

<tasks>

<task type="auto">
  <name>Task 1: Kafka Docker Compose + clicks table migration</name>
  <files>
    docker-compose.yml
    services/migrations/000003_add_clicks_enrichment.up.sql
    services/migrations/000003_add_clicks_enrichment.down.sql
    Makefile
  </files>
  <action>
    1. **Add Kafka to docker-compose.yml** using official `apache/kafka:3.7.0` image in KRaft mode (no ZooKeeper):
       ```yaml
       kafka:
         image: apache/kafka:3.7.0
         ports:
           - "9092:9092"
         environment:
           KAFKA_NODE_ID: 1
           KAFKA_PROCESS_ROLES: broker,controller
           KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
           KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
           KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
           KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
           KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
           KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
           KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
           KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
           KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
           CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
         healthcheck:
           test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092"]
           interval: 10s
           timeout: 10s
           retries: 5
       ```

    2. **Create migration 000003** to add enrichment columns to clicks table:
       - `services/migrations/000003_add_clicks_enrichment.up.sql`:
         ```sql
         ALTER TABLE clicks ADD COLUMN country_code VARCHAR(2) NOT NULL DEFAULT '';
         ALTER TABLE clicks ADD COLUMN device_type VARCHAR(20) NOT NULL DEFAULT '';
         ALTER TABLE clicks ADD COLUMN traffic_source VARCHAR(255) NOT NULL DEFAULT '';
         ```
       - `services/migrations/000003_add_clicks_enrichment.down.sql`:
         ```sql
         ALTER TABLE clicks DROP COLUMN IF EXISTS country_code;
         ALTER TABLE clicks DROP COLUMN IF EXISTS device_type;
         ALTER TABLE clicks DROP COLUMN IF EXISTS traffic_source;
         ```

    3. **Update Makefile**:
       - Add `kafka-up` target: `docker compose up -d kafka`
       - Add `db-migrate` to include the new migration file (000003)
       - Add `run-consumer` target: `go run services/analytics-consumer/consumer.go -f services/analytics-consumer/etc/consumer.yaml`
       - Add `run-all` to include the consumer service
       - Keep all existing targets unchanged
  </action>
  <verify>
    - `docker compose up -d postgres kafka` starts both services
    - `docker compose exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092` returns without error
    - After running db-migrate, `\d clicks` in psql shows country_code, device_type, traffic_source columns
  </verify>
  <done>Kafka broker accessible on localhost:9092, clicks table has all enrichment columns</done>
</task>

<task type="auto">
  <name>Task 2: Install dependencies and scaffold analytics-consumer service</name>
  <files>
    go.mod
    go.sum
    services/analytics-consumer/consumer.go
    services/analytics-consumer/etc/consumer.yaml
    services/analytics-consumer/internal/config/config.go
    services/analytics-consumer/internal/svc/servicecontext.go
  </files>
  <action>
    1. **Install dependencies**:
       ```bash
       go get github.com/zeromicro/go-queue@latest
       go get github.com/oschwald/geoip2-golang@latest
       go get github.com/mileusna/useragent@latest
       ```

    2. **Create `services/analytics-consumer/internal/config/config.go`**:
       ```go
       package config

       import "github.com/zeromicro/go-queue/kq"

       type Config struct {
         kq.KqConf
         DataSource  string
         GeoIPDbPath string `json:",optional"`
       }
       ```
       Use `kq.KqConf` which embeds Brokers, Group, Topic, Offset, Consumers, Processors, etc.

    3. **Create `services/analytics-consumer/etc/consumer.yaml`**:
       ```yaml
       Name: analytics-consumer
       Log:
         ServiceName: analytics-consumer
         Mode: console
         Level: info

       Brokers:
         - 127.0.0.1:9092
       Group: analytics-consumer
       Topic: click-events
       Offset: first
       Consumers: 4
       Processors: 8

       DataSource: postgres://postgres:postgres@localhost:5433/shortener?sslmode=disable
       GeoIPDbPath: data/GeoLite2-Country.mmdb
       ```

    4. **Create `services/analytics-consumer/internal/svc/servicecontext.go`**:
       ```go
       package svc

       import (
         "go-shortener/services/analytics-consumer/internal/config"
         "go-shortener/services/analytics-rpc/model"
         "github.com/zeromicro/go-zero/core/stores/sqlx"
         _ "github.com/lib/pq"
       )

       type ServiceContext struct {
         Config     config.Config
         ClickModel model.ClicksModel
       }

       func NewServiceContext(c config.Config) *ServiceContext {
         conn := sqlx.NewSqlConn("postgres", c.DataSource)
         return &ServiceContext{
           Config:     c,
           ClickModel: model.NewClicksModel(conn),
         }
       }
       ```
       **Important:** Reuse `services/analytics-rpc/model` for ClicksModel. The consumer writes to the same clicks table that analytics-rpc reads from.

    5. **Create `services/analytics-consumer/consumer.go`** (main entry point):
       ```go
       package main

       import (
         "flag"
         "go-shortener/services/analytics-consumer/internal/config"
         "go-shortener/services/analytics-consumer/internal/svc"
         "github.com/zeromicro/go-queue/kq"
         "github.com/zeromicro/go-zero/core/conf"
         "github.com/zeromicro/go-zero/core/logx"
         "github.com/zeromicro/go-zero/core/service"
       )

       var configFile = flag.String("f", "etc/consumer.yaml", "config file")

       func main() {
         flag.Parse()

         var c config.Config
         conf.MustLoad(*configFile, &c)

         svcCtx := svc.NewServiceContext(c)
         _ = svcCtx // Will be used by handler in Plan 09-03

         consumer := kq.MustNewQueue(c.KqConf, kq.WithHandle(func(ctx context.Context, k, v string) error {
           logx.Infow("received click event", logx.Field("key", k), logx.Field("value", v))
           return nil
         }))

         serviceGroup := service.NewServiceGroup()
         defer serviceGroup.Stop()

         serviceGroup.Add(consumer)

         logx.Info("Starting analytics consumer...")
         serviceGroup.Start()
       }
       ```
       Note: This is a placeholder handler that logs messages. Plan 09-03 will replace with the real enrichment handler.

    6. **Run `go mod tidy`** to sync dependencies.
  </action>
  <verify>
    - `go build ./services/analytics-consumer/...` compiles without errors
    - `go vet ./services/analytics-consumer/...` passes
    - go.mod contains `github.com/zeromicro/go-queue`, `github.com/oschwald/geoip2-golang`, `github.com/mileusna/useragent`
  </verify>
  <done>analytics-consumer service compiles, dependencies installed, config/svc/main scaffolded with placeholder handler</done>
</task>

</tasks>

<verification>
1. `docker compose up -d` starts postgres and kafka
2. `docker compose exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092` works
3. Clicks table has country_code, device_type, traffic_source after migration
4. `go build ./services/analytics-consumer/...` compiles
5. `go build ./...` compiles (no regressions)
</verification>

<success_criteria>
- Kafka broker runs on localhost:9092 via Docker Compose (KRaft mode, no ZooKeeper)
- clicks table has enrichment columns (country_code, device_type, traffic_source)
- analytics-consumer service compiles with kq.Queue placeholder
- go-queue, geoip2, useragent dependencies in go.mod
- Makefile has kafka-up and run-consumer targets
</success_criteria>

<output>
After completion, create `.planning/phases/09-messaging-migration/09-01-SUMMARY.md`
</output>
