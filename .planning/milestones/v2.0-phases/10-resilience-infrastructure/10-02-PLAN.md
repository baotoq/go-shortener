---
phase: 10-resilience-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - Dockerfile
  - docker-compose.yml
  - services/url-api/etc/url-docker.yaml
  - services/analytics-rpc/etc/analytics-docker.yaml
  - services/analytics-consumer/etc/consumer-docker.yaml
  - Makefile
autonomous: true

must_haves:
  truths:
    - "docker compose up starts all services (PostgreSQL, Kafka, url-api, analytics-rpc, analytics-consumer)"
    - "url-api container connects to PostgreSQL and Kafka via Docker network service names"
    - "analytics-rpc container connects to PostgreSQL via Docker network"
    - "analytics-consumer container connects to PostgreSQL and Kafka via Docker network"
    - "Services wait for infrastructure health checks before starting"
    - "End-to-end flow works in Docker: shorten → redirect → Kafka → consumer → DB → zRPC query"
  artifacts:
    - path: "Dockerfile"
      provides: "Multi-stage Dockerfile for all three services"
      contains: "CGO_ENABLED=0"
    - path: "docker-compose.yml"
      provides: "Full-stack Docker Compose with all services"
      contains: "url-api"
    - path: "services/url-api/etc/url-docker.yaml"
      provides: "Docker-specific config with container hostnames"
      contains: "postgres:5432"
  key_links:
    - from: "docker-compose.yml"
      to: "Dockerfile"
      via: "build context"
      pattern: "build:"
    - from: "docker-compose.yml"
      to: "services/url-api/etc/url-docker.yaml"
      via: "volume mount"
      pattern: "url-docker.yaml"
---

<objective>
Create Dockerfiles and Docker Compose configuration to run all three microservices alongside PostgreSQL and Kafka in containers with proper health checks, startup ordering, and networking.

Purpose: Satisfy INFR-01 and INFR-02 requirements. Enable one-command full-stack deployment for development and testing.

Output: `docker compose up` starts the entire stack (PostgreSQL, Kafka, url-api, analytics-rpc, analytics-consumer) with correct dependency ordering and inter-service networking.
</objective>

<execution_context>
@/Users/baotoq/.claude/get-shit-done/workflows/execute-plan.md
@/Users/baotoq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-resilience-infrastructure/10-RESEARCH.md
@.planning/phases/10-resilience-infrastructure/10-01-PLAN.md
@docker-compose.yml
@services/url-api/etc/url.yaml
@services/analytics-rpc/etc/analytics.yaml
@services/analytics-consumer/etc/consumer.yaml
@Makefile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create multi-stage Dockerfile</name>
  <files>
    Dockerfile
  </files>
  <action>
    1. **Create `Dockerfile`** at project root with multi-stage build:
       ```dockerfile
       # ========== Build stage ==========
       FROM golang:1.24-alpine AS builder
       WORKDIR /app

       # Cache dependencies
       COPY go.mod go.sum ./
       RUN go mod download

       # Copy source and build all services
       COPY . .

       # Build each service as a separate binary
       RUN CGO_ENABLED=0 GOOS=linux go build -ldflags="-s -w" -o /bin/url-api ./services/url-api/url.go
       RUN CGO_ENABLED=0 GOOS=linux go build -ldflags="-s -w" -o /bin/analytics-rpc ./services/analytics-rpc/analytics.go
       RUN CGO_ENABLED=0 GOOS=linux go build -ldflags="-s -w" -o /bin/analytics-consumer ./services/analytics-consumer/consumer.go

       # ========== URL API ==========
       FROM alpine:3.20 AS url-api
       RUN apk add --no-cache ca-certificates tzdata
       COPY --from=builder /bin/url-api /bin/url-api
       COPY services/url-api/etc /etc/url-api
       EXPOSE 8080 6470
       CMD ["/bin/url-api", "-f", "/etc/url-api/url-docker.yaml"]

       # ========== Analytics RPC ==========
       FROM alpine:3.20 AS analytics-rpc
       RUN apk add --no-cache ca-certificates tzdata
       COPY --from=builder /bin/analytics-rpc /bin/analytics-rpc
       COPY services/analytics-rpc/etc /etc/analytics-rpc
       EXPOSE 8081 6471
       CMD ["/bin/analytics-rpc", "-f", "/etc/analytics-rpc/analytics-docker.yaml"]

       # ========== Analytics Consumer ==========
       FROM alpine:3.20 AS analytics-consumer
       RUN apk add --no-cache ca-certificates tzdata
       COPY --from=builder /bin/analytics-consumer /bin/analytics-consumer
       COPY services/analytics-consumer/etc /etc/analytics-consumer
       EXPOSE 6472
       CMD ["/bin/analytics-consumer", "-f", "/etc/analytics-consumer/consumer-docker.yaml"]
       ```

       **Design decisions:**
       - Single Dockerfile with named build targets (url-api, analytics-rpc, analytics-consumer)
       - Each service is a separate final stage using `AS` target names
       - Docker Compose uses `target` field to select which stage to build
       - `-ldflags="-s -w"` strips debug symbols for smaller binaries
       - Alpine 3.20 for small base image with ca-certificates for TLS
       - CGO_ENABLED=0 for fully static binaries (no glibc dependency)
  </action>
  <verify>
    - `docker build --target url-api -t go-shortener-url-api .` succeeds
    - `docker build --target analytics-rpc -t go-shortener-analytics-rpc .` succeeds
    - `docker build --target analytics-consumer -t go-shortener-analytics-consumer .` succeeds
    - Image sizes are under 50MB each
  </verify>
  <done>Multi-stage Dockerfile builds all three services as separate small images</done>
</task>

<task type="auto">
  <name>Task 2: Create Docker-specific service configs</name>
  <files>
    services/url-api/etc/url-docker.yaml
    services/analytics-rpc/etc/analytics-docker.yaml
    services/analytics-consumer/etc/consumer-docker.yaml
  </files>
  <action>
    1. **Create `services/url-api/etc/url-docker.yaml`**:
       Copy from url.yaml but replace localhost references with Docker service names:
       ```yaml
       Name: url-api
       Host: 0.0.0.0
       Port: 8080
       Timeout: 30000
       MaxConns: 10000

       DevServer:
         Enabled: true
         Port: 6470
         MetricsPath: /metrics
         HealthPath: /healthz

       Log:
         ServiceName: url-api
         Mode: console
         Level: info

       BaseUrl: http://localhost:8080

       DataSource: postgres://postgres:postgres@postgres:5432/shortener?sslmode=disable

       KqPusherConf:
         Brokers:
           - kafka:9092
         Topic: click-events

       AnalyticsRpc:
         Target: dns:///analytics-rpc:8081
         NonBlock: true
         Timeout: 2000
       ```

       **Key differences from url.yaml:**
       - `DataSource`: `postgres:5432` instead of `localhost:5433` (Docker internal port)
       - `KqPusherConf.Brokers`: `kafka:9092` instead of `localhost:9092`
       - `AnalyticsRpc.Target`: `dns:///analytics-rpc:8081` instead of `dns:///localhost:8081`

    2. **Create `services/analytics-rpc/etc/analytics-docker.yaml`**:
       ```yaml
       Name: analytics-rpc
       ListenOn: 0.0.0.0:8081

       DevServer:
         Enabled: true
         Port: 6471
         MetricsPath: /metrics
         HealthPath: /healthz

       Log:
         ServiceName: analytics-rpc
         Mode: console
         Level: info

       DataSource: postgres://postgres:postgres@postgres:5432/shortener?sslmode=disable
       ```

    3. **Create `services/analytics-consumer/etc/consumer-docker.yaml`**:
       ```yaml
       Name: analytics-consumer

       DevServer:
         Enabled: true
         Port: 6472
         MetricsPath: /metrics
         HealthPath: /healthz

       Log:
         ServiceName: analytics-consumer
         Mode: console
         Level: info

       DataSource: postgres://postgres:postgres@postgres:5432/shortener?sslmode=disable

       KqConsumerConf:
         Name: clickEventConsumer
         Brokers:
           - kafka:9092
         Group: analytics-consumer
         Topic: click-events
         Offset: first
         Consumers: 4
         Processors: 4

       GeoIPPath: ""
       ```

       **Note:** `GeoIPPath: ""` — GeoIP database not included in Docker image (optional, falls back to "XX").
  </action>
  <verify>
    - All three Docker config files exist and have Docker service names as hostnames
    - No references to `localhost` for infrastructure services in Docker configs
    - `GeoIPPath` is empty in consumer Docker config
  </verify>
  <done>Docker-specific YAML configs with container-internal hostnames for all three services</done>
</task>

<task type="auto">
  <name>Task 3: Update Docker Compose with application services and Makefile targets</name>
  <files>
    docker-compose.yml
    Makefile
  </files>
  <action>
    1. **Update `docker-compose.yml`** to add the three application services:
       ```yaml
       services:
         postgres:
           image: postgres:16-alpine
           ports:
             - "5433:5432"
           environment:
             POSTGRES_USER: postgres
             POSTGRES_PASSWORD: postgres
             POSTGRES_DB: shortener
           volumes:
             - postgres-data:/var/lib/postgresql/data
             - ./services/migrations:/docker-entrypoint-initdb.d
           healthcheck:
             test: ["CMD-SHELL", "pg_isready -U postgres"]
             interval: 5s
             timeout: 5s
             retries: 5

         kafka:
           image: apache/kafka:3.7.0
           ports:
             - "9092:9092"
           environment:
             KAFKA_NODE_ID: 1
             KAFKA_PROCESS_ROLES: broker,controller
             KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
             KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
             KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
             KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
             KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
             KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
             KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
             KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
             KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
             CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
           volumes:
             - kafka-data:/tmp/kraft-combined-logs
           healthcheck:
             test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list"]
             interval: 10s
             timeout: 10s
             retries: 5
             start_period: 30s

         analytics-rpc:
           build:
             context: .
             dockerfile: Dockerfile
             target: analytics-rpc
           ports:
             - "8081:8081"
             - "6471:6471"
           depends_on:
             postgres:
               condition: service_healthy
           restart: unless-stopped

         url-api:
           build:
             context: .
             dockerfile: Dockerfile
             target: url-api
           ports:
             - "8080:8080"
             - "6470:6470"
           depends_on:
             postgres:
               condition: service_healthy
             kafka:
               condition: service_healthy
             analytics-rpc:
               condition: service_started
           restart: unless-stopped

         analytics-consumer:
           build:
             context: .
             dockerfile: Dockerfile
             target: analytics-consumer
           ports:
             - "6472:6472"
           depends_on:
             postgres:
               condition: service_healthy
             kafka:
               condition: service_healthy
           restart: unless-stopped

       volumes:
         postgres-data:
         kafka-data:
       ```

       **Design decisions:**
       - `KAFKA_ADVERTISED_LISTENERS` changed from `PLAINTEXT://localhost:9092` to `PLAINTEXT://kafka:9092` so app containers can reach Kafka via Docker DNS. For local dev (services outside Docker), still use `localhost:9092` with the non-Docker configs.
       - PostgreSQL migrations are auto-applied via `docker-entrypoint-initdb.d` volume mount (only runs on first database creation, not on every restart). The migration SQL files have numeric prefixes so they execute in order.
       - `analytics-rpc` starts after postgres is healthy (needs DB for click queries)
       - `url-api` starts after postgres, kafka, and analytics-rpc (needs all three)
       - `analytics-consumer` starts after postgres and kafka (needs both for event processing)
       - `restart: unless-stopped` for automatic restart on failure
       - DevServer ports exposed for Prometheus scraping from host

       **Important note about KAFKA_ADVERTISED_LISTENERS change:**
       This changes the advertised listener from `localhost:9092` to `kafka:9092`, which means **local development services running outside Docker** will no longer be able to connect to Kafka using the existing configs. The local dev configs (url.yaml, consumer.yaml) still reference `localhost:9092` and will work when Kafka is started standalone with `make kafka-up` (since the compose file for infra-only use should advertise localhost).

       **Resolution:** Use a Docker Compose profile or override file. The simplest approach: when running `make kafka-up` (infra only), keep `KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092`. When running `docker compose up` (full stack), override to `kafka:9092`. Implement this by adding a `docker-compose.override.yml` or by keeping `localhost:9092` as the advertised listener and adding a second listener for Docker networking.

       **Revised Kafka approach — dual listeners:**
       ```yaml
       kafka:
         environment:
           KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
           KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
           KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
         ports:
           - "9092:29092"
       ```
       This way:
       - Docker containers connect via `kafka:9092` (PLAINTEXT listener)
       - Local dev services connect via `localhost:9092` which maps to host port 29092 (PLAINTEXT_HOST listener)

       Update local dev YAML configs to use `localhost:9092` (unchanged, maps to 29092 on host).

    2. **Update `Makefile`** to add Docker build/run targets:
       ```makefile
       # Add to .PHONY line
       .PHONY: docker-build docker-up docker-down docker-logs

       docker-build: ## Build Docker images for all services
       	docker compose build

       docker-up: ## Start all services in Docker
       	docker compose up -d

       docker-down: ## Stop all Docker services
       	docker compose down

       docker-logs: ## Follow logs for all Docker services
       	docker compose logs -f
       ```

       Keep all existing targets unchanged. Add the new targets at the end of the Makefile.
  </action>
  <verify>
    - `docker compose build` builds all three service images without errors
    - `docker compose up -d` starts all services
    - `docker compose ps` shows all 5 services running (postgres, kafka, url-api, analytics-rpc, analytics-consumer)
    - `curl http://localhost:8080/api/v1/urls` responds (url-api is reachable)
    - `curl http://localhost:6470/metrics` returns Prometheus metrics
    - End-to-end: Create short URL, visit it, check analytics — all works within Docker
    - `make kafka-up && make run-url` still works for local dev (dual listener Kafka)
  </verify>
  <done>Docker Compose starts entire stack with health checks, startup ordering, and dual Kafka listeners for both Docker and local dev</done>
</task>

</tasks>

<verification>
1. `docker compose build` builds all images successfully
2. `docker compose up -d` starts postgres, kafka, analytics-rpc, url-api, analytics-consumer
3. All health checks pass (`docker compose ps` shows "healthy" for postgres and kafka)
4. `curl -X POST http://localhost:8080/api/v1/urls -H 'Content-Type: application/json' -d '{"original_url":"https://example.com"}'` returns short URL
5. `curl -i http://localhost:8080/{code}` returns 302 redirect
6. `curl http://localhost:8080/api/v1/links/{code}` returns link detail with click count
7. `curl http://localhost:6470/metrics` shows Prometheus metrics
8. `docker compose down` cleanly stops all services
9. Local dev workflow still works: `make db-up && make kafka-up && make run-all`
</verification>

<success_criteria>
- Single Dockerfile builds all three services via named targets
- Docker Compose starts full stack: PostgreSQL, Kafka, url-api, analytics-rpc, analytics-consumer
- Health checks ensure correct startup ordering (infrastructure before application)
- Docker configs use container hostnames (postgres, kafka, analytics-rpc)
- Dual Kafka listeners support both Docker-internal and localhost connections
- End-to-end flow works in Docker
- Makefile has docker-build, docker-up, docker-down, docker-logs targets
- Local dev workflow (outside Docker) still works
</success_criteria>

<output>
After completion, create `.planning/phases/10-resilience-infrastructure/10-02-SUMMARY.md`
</output>
